{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating data with MDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searches using `Forge.search()` are limited to 10,000 results. However, there are two methods to circumvent this restriction: `Forge.aggregate_source()` and `Forge.aggregate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from mdf_forge.forge import Forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = Forge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate_source - NIST XPS DB\n",
    "Example: We want to collect all records from the NIST XPS Database and analyze the quality metrics. This database has almost 30,000 records, so we have to use `aggregate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29189/29189 [00:27<00:00, 1067.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First, let's aggregate all the nist_xps_db data.\n",
    "all_entries = mdf.aggregate_source(\"nist_xps_db\")\n",
    "print(len(all_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 15940, 'good': 4, 'Good': 1615, 'Adequate': 11630}\n"
     ]
    }
   ],
   "source": [
    "# Now, let's parse out the \"Quality of Data\" and print te results for analysis.\n",
    "qualities = {}\n",
    "for record in all_entries:\n",
    "    if record[\"mdf\"][\"resource_type\"] == \"record\":\n",
    "        raw = json.loads(record[\"mdf\"][\"raw\"])\n",
    "        if raw[\"Quality of Data\"] in qualities.keys():\n",
    "            qualities[raw[\"Quality of Data\"]] += 1\n",
    "        else:\n",
    "            qualities[raw[\"Quality of Data\"]] = 1\n",
    "print(qualities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregate - Multiple Datasets\n",
    "Example: We want to analyze how often elements are studied with Gallium (Ga), and what the most frequent elemental pairing is. There are more than 10,000 records containing Gallium data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29168/29168 [01:07<00:00, 298.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First, let's aggregate everything that has \"Ga\" in the list of elements.\n",
    "all_results = mdf.aggregate(\"mdf.elements:Ga\")\n",
    "print(len(all_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Ac\": 651,\n",
      "    \"Ag\": 588,\n",
      "    \"Al\": 576,\n",
      "    \"Ar\": 2,\n",
      "    \"As\": 1330,\n",
      "    \"Au\": 649,\n",
      "    \"B\": 681,\n",
      "    \"Ba\": 802,\n",
      "    \"Be\": 496,\n",
      "    \"Bi\": 583,\n",
      "    \"Br\": 127,\n",
      "    \"C\": 1843,\n",
      "    \"Ca\": 682,\n",
      "    \"Cd\": 581,\n",
      "    \"Ce\": 639,\n",
      "    \"Cl\": 672,\n",
      "    \"Co\": 954,\n",
      "    \"Cr\": 712,\n",
      "    \"Cs\": 552,\n",
      "    \"Cu\": 817,\n",
      "    \"Dy\": 600,\n",
      "    \"Er\": 670,\n",
      "    \"Eu\": 614,\n",
      "    \"F\": 344,\n",
      "    \"Fe\": 793,\n",
      "    \"Ga\": 29168,\n",
      "    \"Gd\": 612,\n",
      "    \"Ge\": 776,\n",
      "    \"H\": 1933,\n",
      "    \"Hf\": 659,\n",
      "    \"Hg\": 534,\n",
      "    \"Ho\": 598,\n",
      "    \"I\": 187,\n",
      "    \"In\": 603,\n",
      "    \"Ir\": 557,\n",
      "    \"K\": 698,\n",
      "    \"La\": 960,\n",
      "    \"Li\": 990,\n",
      "    \"Lu\": 527,\n",
      "    \"Mg\": 955,\n",
      "    \"Mn\": 715,\n",
      "    \"Mo\": 606,\n",
      "    \"N\": 1402,\n",
      "    \"Na\": 840,\n",
      "    \"Nb\": 564,\n",
      "    \"Nd\": 616,\n",
      "    \"Ni\": 836,\n",
      "    \"Np\": 506,\n",
      "    \"O\": 4031,\n",
      "    \"Os\": 668,\n",
      "    \"P\": 676,\n",
      "    \"Pa\": 607,\n",
      "    \"Pb\": 544,\n",
      "    \"Pd\": 653,\n",
      "    \"Pm\": 624,\n",
      "    \"Pr\": 714,\n",
      "    \"Pt\": 743,\n",
      "    \"Pu\": 535,\n",
      "    \"Rb\": 588,\n",
      "    \"Re\": 498,\n",
      "    \"Rh\": 584,\n",
      "    \"Ru\": 562,\n",
      "    \"S\": 512,\n",
      "    \"Sb\": 632,\n",
      "    \"Sc\": 715,\n",
      "    \"Se\": 374,\n",
      "    \"Si\": 1075,\n",
      "    \"Sm\": 773,\n",
      "    \"Sn\": 606,\n",
      "    \"Sr\": 711,\n",
      "    \"Ta\": 558,\n",
      "    \"Tb\": 591,\n",
      "    \"Tc\": 508,\n",
      "    \"Te\": 758,\n",
      "    \"Th\": 519,\n",
      "    \"Ti\": 693,\n",
      "    \"Tl\": 687,\n",
      "    \"Tm\": 590,\n",
      "    \"U\": 507,\n",
      "    \"V\": 714,\n",
      "    \"W\": 563,\n",
      "    \"Xe\": 1,\n",
      "    \"Y\": 724,\n",
      "    \"Yb\": 741,\n",
      "    \"Zn\": 672,\n",
      "    \"Zr\": 648\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Now, let's parse out the other elements in each record and keep a running tally to print out.\n",
    "elements = {}\n",
    "for record in all_results:\n",
    "    if record[\"mdf\"][\"resource_type\"] == \"record\":\n",
    "        elems = record[\"mdf\"][\"elements\"]\n",
    "        for elem in elems:\n",
    "            if elem in elements.keys():\n",
    "                elements[elem] += 1\n",
    "            else:\n",
    "                elements[elem] = 1\n",
    "print(json.dumps(elements, sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
